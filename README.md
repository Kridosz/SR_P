# SpeechRecognition_Python
 Python-Driven Emotion Recognition through Librosa

I will use various libraries in this Python mini project, including librosa, sound file, and sklearn, to build a model using an MLPClassifier. The primary objective of this project is to create a model that can recognize emotions from sound files. I'll start by loading the data, extracting its essential features, and splitting the dataset into training and testing sets. The next step involves initializing an MLPClassifier and training the model using the training data. Finally, I'll evaluate the model's accuracy to assess its performance.

For this project, I have chosen to work with the RAVDESS dataset, the Ryerson Audio-Visual Database of Emotional Speech and Song. It contains a vast collection of 7356 files, rated by 247 individuals on emotional validity, intensity, and genuineness. I utilized the Soundfile library to read the sound files and the librosa library to extract relevant features from them. The model I built achieved an accuracy of 72.4%, which meets my expectations and requirements.

While I acknowledge room for improvement, a 72.4% accuracy is considered satisfactory for my current needs. I have gained valuable insights into audio-based emotion recognition and laid a foundation for future enhancements.
